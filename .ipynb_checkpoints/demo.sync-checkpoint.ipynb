{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818912be",
   "metadata": {
    "cell_marker": "\"\"\"",
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ffd472",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "try:\n",
    "    with open(os.path.expanduser(\"~/.cache/oai\"), \"r\") as f:\n",
    "        openai.api_key = f.read().strip()\n",
    "except:\n",
    "    print(\"Error reading openai api key from ~/.cache/oai\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d5417",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# The Functions API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5fabe",
   "metadata": {
    "cell_marker": "r\"\"\"",
    "heading_collapsed": true
   },
   "source": [
    "## The intended use case\n",
    "\n",
    "As presented by OpenAI, functions in the chat models are meant to be used to get\n",
    "the model to generate function arguments.\n",
    "\n",
    "The idea is you ask the model a question and provide it function descriptions,\n",
    "then if the question seems suitable for a function, the model will generate\n",
    "the arguments for the function rather than answer the question directly.\n",
    "\n",
    "The dev can then easily pass the generated arguments to the function and call it,\n",
    "either to provide the output to the user, or to pass back to the model and get \n",
    "another response with the result in context.\n",
    "\n",
    "\\\n",
    "**TLDR**\n",
    "- meant to be used to get the model to generate function arguments\n",
    "- ask the model a question and provide it function descriptions\n",
    "- if the question seems suitable for a function, the model will generate args\n",
    "- then pass args to the function\n",
    "- give result to user, or pass back to model and get another response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db1097",
   "metadata": {
    "cell_marker": "\"\"\"",
    "hidden": true
   },
   "source": [
    "To illustrate, here a simplified version of the example OpenAI gives in their docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80bd9fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dummy function to demonstrate\n",
    "def get_weather(location, unit=\"c\"):\n",
    "    \"\"\"Get the weather in a location\"\"\"\n",
    "    # in reality you'd call some api here with the args\n",
    "    weather = {\n",
    "        \"location\": location,\n",
    "        \"unit\": unit,\n",
    "        \"temperature\": 20,\n",
    "        \"condition\": \"sunny\",\n",
    "    }\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5eb2e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': <OpenAIObject at 0x7f60e7f50cb0> JSON: {\n",
       "   \"name\": \"get_weather\",\n",
       "   \"arguments\": \"{\\n  \\\"location\\\": \\\"Kingston\\\"\\n}\"\n",
       " }}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = \"What's the weather like in Kingston?\"\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\", # until old models are deprec, use -0614\n",
    "    messages=[{\"role\": \"user\", \"content\": msg}],\n",
    "    functions=[  # list of dicts\n",
    "        {\n",
    "            \"name\": \"get_weather\",  # name of function\n",
    "            \"description\": \"Get the weather in a location\",  # description of function\n",
    "            \"parameters\": {  # parameters of function\n",
    "                \"type\": \"object\",  # type of parameters (almost always object)\n",
    "                \"properties\": {  # the function arguments\n",
    "                    \"location\": {  # arg\n",
    "                        \"type\": \"string\",  # arg type (any json type)\n",
    "                        \"description\": \"The location to get the weather for\",  # arg description\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The unit to return the temperature in\",\n",
    "                        # can enumerate the possible values instead of leaving openended\n",
    "                        \"enum\": [\"f\", \"c\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],  # list required args\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call=\"auto\",  # \"auto\" or a function name\n",
    ")\n",
    "\n",
    "res_content = res.choices[0].message.to_dict()  # type: ignore\n",
    "res_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fd26c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "hidden": true
   },
   "source": [
    "when it calls a function, there is nothing in the content field, only function_call\n",
    "\n",
    "(and vice versa)\n",
    "\n",
    "so, if we want to then call the function and show the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a88c9d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Kingston', 'unit': 'c', 'temperature': 20, 'condition': 'sunny'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_to_call = res_content[\"function_call\"][\"name\"]\n",
    "args = json.loads(res_content[\"function_call\"][\"arguments\"])\n",
    "\n",
    "weather = globals()[func_to_call](**args)\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a232efda",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Kingston is 20°c and sunny\n"
     ]
    }
   ],
   "source": [
    "# and so you could show it back to the user like this:\n",
    "print(\n",
    "    f\"The weather in {args['location']} is {weather['temperature']}°{weather['unit']} and {weather['condition']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cec35d",
   "metadata": {
    "cell_marker": "\"\"\"",
    "hidden": true
   },
   "source": [
    "This alone is pretty cool and very useful. Like a more powerful/extensible version of\n",
    "plugins in chatGPT that we can write ourselves for any usecase. \n",
    "\n",
    "Some stuff you guys might want to use it for is using wolfram alpha, wikipedia,\n",
    "investopedia, or looking up cases or medical information in a database etc.\n",
    "\n",
    "Sort of just substitutes langchain in a lot of places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b33a8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## The more powerful use case\n",
    "\n",
    "The new versions of the models which have the functions api were of course finetuned \n",
    "on tons of data to give these structured argument outputs. So, we can exploit that\n",
    "to get the model to generate any structured data we want. I don't think I can overstate\n",
    "how useful this is when trying to get it to conform to some output form, for pretty much\n",
    "any application.\n",
    "\n",
    "_The caveat is we need to \"trick\" it into thinking it's generating function arguments._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d15a6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Here's how I used it in my work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be5dc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thinking': ['Standard I (B): Independence and Objectivity requires CFA members to maintain independence and objectivity when making investment decisions or issuing recommendations.',\n",
       "  'In this case, the manager is trying to prevent Phil Jones from stating any unfavorable opinions about Alpha One.',\n",
       "  'This action by the manager suggests a potential violation of the independence and objectivity standard.',\n",
       "  \"The manager is compromising the independence and objectivity of Phil Jones' research report for the benefit of the firm's relationship with Alpha One.\",\n",
       "  'Therefore, the correct answer is B: The manager preventing Phil Jones from stating any unfavorable opinions about Alpha One.'],\n",
       " 'answer': 'B'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_prompt = \"\"\"You are a CFA (chartered financial analyst) taking a test to evaluate your knowledge of finance.\n",
    "You will be given a question along with three possible answers (A, B, and C).\n",
    "Before answering, you should think through the question step-by-step.\n",
    "Explain your reasoning at each step towards answering the question.\n",
    "If calculation is required, do each step of the calculation as a step in your reasoning.\n",
    "Finally, indicate the correct answer\n",
    "\"\"\"\n",
    "\n",
    "question = \"Phil Jones, CFA, has just finished researching Alpha One Inc. and is about to issue an unfavorable report on the company. His manager does not want him to state any adverse opinions about Alpha One, as it could adversely affect their firm’s relations with the company, which is an important investment banking client. Which of the following actions by the manager most likely violates Standard I (B): Independence and Objectivity?\"\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"answer_question\",\n",
    "            # tell it what the \"function\" should do\n",
    "            \"description\": \"Thinks through and answers a multiple choice question on finance\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {  # use args to tell it what fields it should generate\n",
    "                    \"thinking\": {\n",
    "                        \"type\": \"array\",  # arrays will be arbitrary length\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Thought and/or calculation for a step in the process of answering the question\",\n",
    "                        },\n",
    "                        \"description\": \"Step by step thought process and calculations towards answering the question\",\n",
    "                    },\n",
    "                    \"answer\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The answer to the question\",\n",
    "                        # use enum to restrain its output for easy parsing\n",
    "                        \"enum\": [\"A\", \"B\", \"C\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"thinking\", \"answer\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"answer_question\"},\n",
    ")\n",
    "ans = res.choices[0].message.to_dict()[\"function_call\"][\"arguments\"]  # type: ignore\n",
    "out = json.loads(ans)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf06d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Standard I (B): Independence and Objectivity requires CFA members to maintain independence and objectivity when making investment decisions or issuing recommendations.\n",
      "2. In this case, the manager is trying to prevent Phil Jones from stating any unfavorable opinions about Alpha One.\n",
      "3. This action by the manager suggests a potential violation of the independence and objectivity standard.\n",
      "4. The manager is compromising the independence and objectivity of Phil Jones' research report for the benefit of the firm's relationship with Alpha One.\n",
      "5. Therefore, the correct answer is B: The manager preventing Phil Jones from stating any unfavorable opinions about Alpha One.\n",
      "\n",
      "Answer: B\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(out[\"thinking\"]):\n",
    "    print(f\"{i+1}. {line}\")\n",
    "\n",
    "print(\"\\nAnswer:\", out[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ba369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct\n"
     ]
    }
   ],
   "source": [
    "answer = \"B\"\n",
    "if out[\"answer\"] == answer:\n",
    "    print(\"Correct\")\n",
    "else:\n",
    "    print(\"Failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3258930",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Without functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abfc6e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before identifying the possible violation, let's first understand what Standard I (B): Independence and Objectivity states. It says that CFA members and candidates must maintain independence and objectivity in their professional activities. They must not offer any services that create a conflict of interest, compromise their independence, or impair their objectivity.\n",
      "\n",
      "With this in mind, let's review the actions of the manager.\n",
      "\n",
      "The manager does not want Phil Jones to state any adverse opinions about Alpha One Inc, which is a potential investment banking client.\n",
      "\n",
      "This action by the manager violates Standard I (B): Independence and Objectivity. It compromises Phil Jones' independence and objectivity in his professional activities. Phil Jones should provide a fair and honest assessment of his research on Alpha One Inc, regardless of the possible impact on their firm’s relations with the company.\n",
      "\n",
      "Therefore, the correct answer is: [[A]] The manager instructs Phil Jones to issue a favorable report on Alpha One Inc.\n"
     ]
    }
   ],
   "source": [
    "# sys_prompt last line: \"Finally output the correct answer\"\n",
    "sys_prompt_nofunc = (\n",
    "    sys_prompt + \" in brackets as such: [[answer]] where answer is A, B, or C\"\n",
    ")\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt_nofunc},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ],\n",
    ")\n",
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecba41",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "While _most_ of the time it will listen to your formatting request, it's not guaranteed\n",
    "and often adds some verbose explanation around your formatted output. \n",
    "\n",
    "This makes parsing annoyingly inconsistent, and for applications more complicated than this\n",
    "it may introduce countless edge cases and issues. Overall, its just not a headache \n",
    "you need to deal with anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ce30e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Even for user queries it can be nicer to use functions to get clean structured output\n",
    "instead of messy inconsistent text. How about getting code help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f588b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"In python, how do you print a string with variables, and format the numbers to 2 decimal places?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1338889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can print a string with variables and format the numbers to 2 decimal places in python using f-strings. Here's an example:\n",
      "\n",
      "```\n",
      "num1 = 3.14159\n",
      "num2 = 2.71828\n",
      "result = num1 + num2\n",
      "\n",
      "print(f\"The sum of {num1:.2f} and {num2:.2f} is {result:.2f}\")\n",
      "```\n",
      "\n",
      "Output:\n",
      "```\n",
      "The sum of 3.14 and 2.72 is 5.86\n",
      "``` \n",
      "\n",
      "In the f-string, the curly braces {} are used as placeholders for the variables. The \".2f\" inside the curly braces formats the variable value as a float rounded to 2 decimal places.\n"
     ]
    }
   ],
   "source": [
    "sys_prompt = \"\"\"You are a helpful programming assistant that can answer questions about code.\n",
    "When the question is about syntax or how to do something in a specific language, you should\n",
    "respond only with the code. Otherwise give an answer as normal.\n",
    "\"\"\"\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ],\n",
    ")\n",
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae11737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age = 25\n",
      "gpa = 3.78\n",
      "\n",
      "print(f\"My age is {age} and my GPA is {gpa:.2f}\")\n"
     ]
    }
   ],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": sys_prompt}, # don't even need a sys prompt\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"code_help\",\n",
    "            \"description\": \"Gives the corresponding code for an answer to a question about programming\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"code\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Lines of code constituting the answer to the coding question\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"code\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"code_help\"},\n",
    ")\n",
    "ans = res.choices[0].message.to_dict()[\"function_call\"][\"arguments\"]  # type: ignore\n",
    "out = json.loads(ans)\n",
    "print(out[\"code\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
